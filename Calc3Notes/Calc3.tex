\documentclass{article}
\usepackage{graphicx}
\usepackage{physics}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{array, esint}

\title{Calculus 3 notes}
\author{Joe Hollander}
\date{Summer 2024}  

\begin{document}
\maketitle


\section*{Vector Functions}
\noindent Dot product: 
\[a \cdot b = |a||b|cos(\theta).\]
Cross product:
To find the cross product of a and b find the
determinant of 3x3 matrix with unit vectors: $\mathbf{i, j, k}$
for the first row. Additionally: 
\[|a \times  b| = |a|b|sin(\theta).\]

The vector equation of a line starting at point $P$, $(a, b, c)$, 
with parralel vector $\vec{v}$, $\left\langle d, e, f\right\rangle$,
and paramater $t$:
\[
r(t) = P + t\vec{v} = 
\left\langle a + dt, b + et, c + ft\right\rangle.
\]

Given a constant point on the plane $P_0$, $(x_0,y_0,z_0)$
and a point on the plane $P$, $(x,y,z)$, 
the vector $\vec{P_0P}$ must be orthogonal to the normal vector of the plane $N$, 
$\left\langle A,B,C \right\rangle$.
Therefore, \[N \cdot \vec{P_0P} = 0, \]
and \[A(x-x_0) + B(y-y_0) + C(z-z_0) = 0.\]

Given vector function $r(t) = \left\langle f(t), g(t), h(t) \right\rangle$,
\[r'(t) = \left\langle f'(t), g'(t), h'(t) \right\rangle,\] and 
\[R(t) = \left\langle F(t), G(t), H(t) \right\rangle.\]


Length of curve from a to b is: \[\int_{a}^{b} |r'(t)| dt,\]
\[s(t) = \int_{0}^{t} |r'(x)| dx.\] An equation $y = f(x)$ can be paramaterized as
$r(t) = \left\langle t, f(t) \right\rangle$. 

The unit tangent vector: $T(t) = r'(t)/|r'(t)|$.
The principle unit normal vector: $N(t) = T'(t)/|T'(t)|$.
The binomial vector: $B = T \times N$. The osculating plane is
the one formed by $T$ and $N$. 
Curvature:
\[
\kappa(x) = |\frac{dT}{ds}| = \frac{|T'(t)|}{|r'(t)|}
= \frac{|r'(t) \times r''(t)|}{|r'(t)|^3}
\]
Torsion:
\[
\tau(x) = -N \cdot \frac{dB}{ds} 
= \frac{(r'(t) \times r''(t)) \cdot r'''(t)}{|r'(t) \cdot r''(t)|}.
\]

Working backwords from an acceleration vector, $\vec{a}$,
we can derive a position vector function of an object affected 
by gravity.
\[\vec{a} = \left\langle0, -9.8\right\rangle.\]
Given an initial velocity vector, $\vec{v_0}$ with speed, $s$,
and angle, $\alpha$: 
\[\vec{v_0} = \left\langle s\cos(\alpha), s\sin(\alpha)\right\rangle,\]
\[v(t) = \left\langle s\cos(\alpha), -9.8t + s\sin(\alpha)\right\rangle,\]
and
\[r(t) = \left\langle s\cos(\alpha)t, -4.9t^2 + s\sin(\alpha)t\right\rangle,\]
\[x = s\cos(\alpha)t, y = -4.9t^2 + s\sin(\alpha)t\].

\section*{Partial Derivatives}

Domain for a function of two variables can be written as: 
\[D = \{(x,y) \ | \ x + y != 2, \ xy < -1\}.\]
Similar to contour drawings on maps, level curves of a function $f$ of two variables
are the curves with equations $f(x,y) = k$ where $k$ is a constant. 
\begin{center}
    \includegraphics[width=12cm,height=12cm, keepaspectratio]{Images/LevelCurves.png}
\end{center}
Functions of three variables are the same as functions of two variables and
functions of multiple variables can be packaged into a function of one vector
variable. 

For multivariable limits, the notation is:
\[\lim_{(x,y)\to (a,b)}f(x,y) = L.\]
Since the limit of a multi variable function can be approached from any way,
the definition of what makes a limit not exist has to be redefined. If 
$f(x,y) \to L_1$ as $(x,y) \to (a,b)$ along a path $C_1$ and $f(x,y) \to L_2$ as
$(x,y) \to (a,b)$ along a path $C_2$ and $L_1 \neq L_2$, then $\lim_{(x,y)\to (a,b)}f(x,y)$
does not exist. The easiest paths to evaluate are often the x and y-axis. 
If evaluating on the x-axis (or y-axis) substitute in $y=b$ (or $x=a$) and then solve
\[\lim_{(x,y) \to (a, b)} f(x,b),\] or \[\lim_{(x,y) \to (a, b)} f(a,y).\] 
Substituting in $y = mx$ is also an easy path to evaluate. A polynomial function of two variables
is in the form: \[f(x,y) = cx^n y^n.\] A rational polynomial is the ratio of two polynomials.
Since a polynomial is continous everywhere, a polynomial $p$ has the property:
\[\lim_{(x,y) \to (a,b)} p(x,y) = p(a,b).\]
Similarly a rational function $q$ has the same property provided $r(a,b) \neq 0$:
\[\lim_{(x,y) \to (a,b)} q(x,y) = \frac{p(a,b)}{r(a,b)} = q(a,b).\]
Squeeze theorem applies to multivariable functions also. Additionally,
the epsilon-delta definition of a limit is useful in proving that the limit is a value.
The definition states that for every $\epsilon > 0$ there exists a $\delta > 0$. 
$\delta$ bounds the domain such that:
\[0 < \sqrt{(x-a)^2 + (y-b)^2} < \delta,\]
and $\epsilon$ bounds the range such that: \[|f(x,y) - L| < \epsilon.\]
It's often easiest to start with the epsilon inequality first,
and finding a relation between delta and epsilon such as $\delta = \epsilon/3$
completes the proof. The epsilon-delta definition extends to vector functions:
\[0 < |\vec{x} - \vec{a}| < \delta, \] and
\[|f(\vec{x}) - L| < \epsilon.\]

A multivariable function is defined as continous if
\[\lim{(x,y) \to (a,b) f(x,y) = f(a,b)}.\] 
If two functions $f$ and $g$ are continuous then their composition function
$h = f \: \circ g = f(g(x,y))$ is also continous. Fix $y=b$ so that $g(x)=f(x,b)$.
The derivative of $f$ with respect to $x$ at $a$ is denoted by:
\[g'(a) = f_x(a,b).\] Therefore, the limit definition becomes:
\[f_x(a,b) = \lim_{h \to 0}\frac{f(a+h,b) - f(a,b)}{h},\]
or \[f_y(a,b) = \lim_{h \to 0}\frac{f(a,b+h) - f(a,b)}{h}.\]

\noindent Visually: 
\begin{center}
    \includegraphics[width=12cm,height=12cm, keepaspectratio]{Images/PartialDerivative.png}
\end{center}

When implicity differentiating equations with respect to $x$ such as:
\[x^3 + y^3 + z^3 + 6xyz = 0,\] where $z = f(x,y)$. Treat $y$ as a constant and $z$
as a function of $x$. Therefore, the derivative would be:
\[3x^2 + 3z^2\pdv{z}{x} + 6yz + 6xy\pdv{z}{x} = 0.\]
Partial derivatives of functions of three variables are the same. Second order
partial derivatives are denoted as:
\[(f_x)_x = \pdv[2]{f}{x},\]
and partial derivatives of order $n$ are denoted as:
\[\pdv[n]{f}{x}.\]
Clairaut's theorem states that if $f$ is defined on a domain disk $D$ that contains
the point $(a,b)$ then
\[f_{xy}(a,b) = f_{yx}(a,b).\]

Tangent plane contains both tangent lines from the derivative with respect to $x$
and the derivative with respect to $y$.  
\begin{center}
    \includegraphics[width=12cm,height=12cm, keepaspectratio]{Images/TangentPlane.png}
\end{center}

Another equation of a plane is:
\[z-z_0=a(x-x_0) + b(y-y_0),\]
where $a = -A/C$ and $b = -B/C$. Remember the normal vector:
 $N = \left\langle A, B, C \right\rangle.$ Since setting $y=y_0$ or
 $x=x_0$ represents the tangent line in the $x$ or $y$ plane respectively, 
 the equation of a tangent plane given the derivatives with respect to $x$ and $y$
 at the point $(x_0, y_0, z_0)$ is: 
 \[z-z_0 = f_x(x_0, y_0)(x-x_0) + f_y(x_0, y_0)(y-y_0).\]
 This equation can be used to 
 approximate $z$ close to $(x_0, y_0)$. Specifically, this linear function:
 \[L(x,y) = f(a,b) +f_x(a,b)(x-a)+f_y(a,b)(y-b),\] is called
 the linearization for $f$ at $(a,b).$ A two variable function is
considered differentiable at $(a,b)$ if:
\[\Delta z = f_x(a,b)\Delta x + f_y(a,b)\Delta y + \epsilon_1\Delta x + \epsilon_2\Delta y,\]
where $\epsilon_1$ and $\epsilon_2$ are functions of $\Delta x$ and $\Delta y$
such that $\epsilon_1$ and $\epsilon_2 \to 0$ as $(\Delta x,\Delta y) \to (0,0).$
Rephrased, if the partial derivatives exist and are continous at $(a,b)$,
then the function is differentiable at $(a,b)$. 

$\Delta z$ is the 
actual change in $z$, while $dz$ is the linear approximation of the change in $z$:
\[dz = \pdv{z}{x}dx + \pdv{z}{y}dy.\]

One of the chain rules for multivariable functions:
\[\dv{z}{t} = \pdv{z}{x}\dv{x}{t} + \pdv{z}{y}\dv{y}{t}.\]
When $x$ and $y$ are functions of two variables $s$ and $t$, 
\[\dv{z}{s} = \pdv{z}{x}\pdv{x}{s} + \pdv{z}{y}\pdv{y}{s},\]
\[\dv{z}{t} = \pdv{z}{x}\pdv{x}{t} + \pdv{z}{y}\pdv{y}{t}.\]
Finding $y'$ from the implicitly defined equation:
\[x^3 + y^3 = 6xy.\]
We can write this equation as:
\[F(x,y) = x^3 + y^3 - 6xy = 0.\]
Knowing that $y$ can be written as a function of $x$ and that 
$F(x,y) = 0$, we can rewrite 
\[\pdv{F}{x} + \pdv{F}{y}\dv{y}{x} = 0,\]
as \[\dv{y}{x} = -\frac{F_x}{F_y}.\]
Therefore, in the above equation 
\[y' = -\frac{F_x}{F_y} = -\frac{x^2 - 2y}{y^2 -2x}.\]
Extending this result, for the equation
\[F(x,y,z)=F(x,y,f(x,y))=0,\]
\[\pdv{z}{x} = -\frac{F_x}{F_z},\] and
\[\pdv{z}{y} = -\frac{F_y}{F_z}.\]

The directional derivative of $f$ at $(x_0, y_0)$ in the direction
of a unit vector $\mathbf{u} = \left\langle a,b \right\rangle$:
\[D_uf(x_0,y_0) = \lim_{h \to 0}\frac{f(x_0 + ha, y_0 + hb) - f(x_0,y_0)}{h}.\]
If $f$ is a directional function of $x$ and $y$, then $f$ has a directional
derivative in the direction of the unit vector $\mathbf{u} = \left\langle a,b \right\rangle$
and \[D_uf(x,y) = f_x(x,y)a + f_y(x,y)b
= \left\langle f_x(x,y),f_y(x,y) \right\rangle \cdot \mathbf{u}
.\]
$\left\langle f_x(x,y),f_y(x,y) \right\rangle$ is called the gradient vector of
$f$ and is also denoted by $\nabla f$. Also defined by:
\[\nabla f(x,y) = \pdv{f}{x}\mathbf{i} + \pdv{f}{y}\mathbf{j}.\]
Therefore, the directional derivative can be written as:
\[D_uf(x,y)=\nabla f(x,y) \cdot \mathbf{u}.\]

The maximum of the directional derivative 
$D_uf(\mathbf{x})$ is $|\nabla f(\mathbf{x})|)$, and it occurs when
$\mathbf{u}$ has the same direction as the gradient vector $\nabla f(\mathbf{x})$.

Given a level surface $F(x,y,z) = k$, the gradient vector $\nabla F$
is perpendicular to the surface, and therefore, the tangent plane to the surface
can be represented by the point and the gradient vector of that point.
Using the standard equation of a plane:
\[F_x(x_0,y_0,z_0)(x-x_0)+F_y(x_0,y_0,z_0)(y-y_0)+F_z(x_0,y_0,z_0)(z-z_0)=0.\]
The normal line is the line perpendicular to the surface at point $(x_0,y_0,z_0)$,
and therefore, its symmetric equations are:
\[\frac{x-x_0}{F_x(x_0,y_0,z_0)} = \frac{y-y_0}{F_y(x_0,y_0,z_0)}
 = \frac{z-z_0}{F_z(x_0,y_0,z_0)}.\]
For an equation defined by $z=f(x,y)$, we can rewrite the equation as:
\[F(x,y,z) = f(x,y) - z = 0.\] In this situation
\[F_x(x_0,y_0,z_0) = f_x(x_0,y_0),\]
\[F_y(x_0,y_0,z_0) = f_y(x_0,y_0),\]
\[F_z(x_0,y_0,z_0) = -1.\]

If $f$ has a local maximum or minimum at $(a,b)$ and the first partial
derivatives exist at $(a,b)$, then $f_x(a,b)=0$ and $f_y(a,b)=0$. Also,
$\nabla f = \mathbf{0}$. The function $f$ has a critical point if $f_x(a,b)=0$, $f_y(a,b)=0$,
or either one of the partial derivatives don't exist. A critical point doesn't
guarantee a maximum or minimum. The second derivatives test:
\[D(a,b)=f_{xx}(a,b)f_{yy}(a,b)-[f_{xy}(a,b)]^2.\]
If $D>0$ and $f_{xx}(a,b)>0$, then $(a,b)$ is a local minimum,
if $D>0$ and $f_{xx}(a,b)<0$, then $(a,b)$ is a local maximum,
and if $D<0$ then $f(a,b)$ is a saddle point.

A closed set in $\mathbb{R}^2$ is one that contains its boundary points, while
a bounded set in $\mathbb{R}^2$ is one contained in a disk. In order to find
maximums and minimums on a closed set, find the critical points inside the set
and then find the critical points on the boundary.

Use given conditions in optimization problem to simplify problem with
less variables.

Lagrange's method seeks maximize $f(x,y)$ given $g(x,y)=k$. The gradient vectors
at the intersection point of $f(x_0,y_0)=c$ and $g(x,y)=k$ must be multiples of 
each other:
\[\nabla f(x_0,y_0) = \lambda \nabla g(x_0,y_0).\]

\noindent Visually: 
\begin{center}
    \includegraphics[width=12cm,height=12cm, keepaspectratio]{Images/LagrangeMultiplier.png}
\end{center}

This method extends to three dimensions where $f(x,y,z)$ is maximized given
$g(x,y,z)=k$. Lagrange's method also assumes that $\nabla g \neq \mathbf{0}$. If $\lambda = 0$, then $\nabla f = \mathbf{0}$ and $(x_0, y_0, z_0)$
is a critical point. The constant $\lambda$ is called a Lagrange multiplier.
In terms of components:
\[\nabla f = \lambda \nabla g,\]
\[f_x = \lambda g_x, f_y = \lambda g_y, f_z = \lambda g_z.\]
Solving these equations given $g(x,y,z)=k$ solves the problem.

Lagrange's method extends to two conditions. Visually: 
\begin{center}
    \includegraphics[width=12cm,height=12cm, keepaspectratio]{Images/TwoConstantLagrangeMultiplier.png}
\end{center}
Therefore, 
\[\nabla f(x_0,y_0,z_0) = \lambda \nabla g(x_0,y_0,z_0) + \mu \nabla h(x_0,y_0,z_0).\]

\section*{Multiple Integrals}

Definition of the volume of a solid $S$ above the $xy$ axis and below $f$
as a double integral and as a riemann sum over the rectangle $R$:

\[V = \iint\limits_R f(x,y) \,dA = \lim_{m,n \to \infty} \sum_{i=1}^{m} \sum_{j=1}^{n} f(x^*_{ij},y^*_{ij}) \, \Delta A,\]
where $(x^*_{ij},y^*_{ij})$ are samples from the $ij$ subdivision. If 
there is a constant $M$ such that $|f(x,y)| <= M$ for all $(x,y)$ in $R$,
and $f$ is continous on $R$, then $f$ is integrable over $R$.

The midpoint rule states:
\[\iint\limits_R f(x,y) \,dA \approx \lim_{m,n \to \infty} \sum_{i=1}^{m} \sum_{j=1}^{n} f(\bar{x_{ij}},\bar{y_{ij}}) \, \Delta A,\]

Partial integration such as:
\[A(x) = \int_{c}^{d} f(x,y) \, dy,\]
is similar to partial derivation and means to integrate with respect to $y$
while keeping $x$ constant. An iterated integral integrates with respect
to one variable after another:
\[ \int_{a}^{b} \int_{c}^{d} f(x,y) \, dy \, dx = \int_{a}^{b} A(x) \, dx.\]
Calculate from the inside out. A rectangle can be defined as 
$R=[a,b] \cross [c,d]$.

The average value of a function of two variables over the rectangle $R$
with area $A(R)$:
\[f_{avg} = \frac{1}{A(R)} \iint \limits_R f(x,y) \, dA.\]
Therefore, if $f(x,y) \ge 0$:
\[A(R) \cross f_{avg} = \iint \limits_R f(x,y) \, dA.\]

To find a double integral over a more general region $D$, 
we define the function:
\[ F(x) = \begin{cases} 
      f(x,y) & (x,y) \in D \\
      0 & (x,y) \in R \notin D
   \end{cases}.
\]
A plane region $D$ is defined as type I when $g_1$ and $g_2$ are continous:
\[D = \{(x,y) \ | \ a \le x \le b, \ g_1(x) \le y \le g_2(x)\}.\]
Type I regions must be continous but don't have to be defined by a single 
formula. Therefore,
\[\iint \limits_D f(x,y) \, dA  = \int_{a}^{b} \int_{g_1(x)}^{g_2(x)} f(x,y) \, dy \, dx.\]
Type II regions are similar to type I regions and are defined as:
\[D = \{(x,y) \ | \ c \le y \le d, \ h_1(y) \le x \le h_2(y)\},\]
where $h_1$ and $h_2$ are continuous. Similarly,
\[\iint \limits_D f(x,y) \, dA  = \int_{c}^{d} \int_{h_1(y)}^{h_2(y)} f(x,y) \, dx \, dy.\]

An example of solving a problem where $D$ is bounded by $y=2x^2$
and $y=1+x^2$. Therefore,
\[D = \{(x,y) \ | \ -1 \le x \le 1, \ {2x^2} \le y \le {1+x^2} \},\]
and:
\[
\begin{split}
\iint \limits_D f(x,y) \, dA & = \int_{-1}^{1} \int_{2x^2}^{1+x^2} (x+2y) \,dy\,dx \\
& = \int_{-1}^{1} [xy+y^2]_{y=2x^2}^{y=1+x^2} \, dx \\
& = \int_{-1}^{1} [x(1+x^2) + (1+x^2)^2 - x(2x^2) + (2x^2)^2] \, dx \\
& = \int_{-1}^{1} (-3x^4-x^3+2x^2+x+1) \, dx \\
& = -3\frac{x^5}{5} - \frac{x^4}{4} + 2\frac{x^3}{3} + \frac{x^2}{2} + x \bigg]_{-1}^{1} = \frac{32}{15}. 
\end{split}
\]

Sometimes it is easier to solve a double integral by changing the order
of integration. For example $D$ can be written as:
\[
D = \{(x,y) \ | \ 0 \le x \le 1, \ 1 \le y \le x\},
\]
and
\[
    D = \{(x,y) \ | \ 0 \le y \le 1, \ 0 \le x \le y\}.
\]


If $D = D_1 \cup D_2$ then:
\[
\iint \limits_D f(x,y) \, dA = \iint \limits_{D_1} f(x,y) \, dA + \iint \limits_{D_2} f(x,y) \, dA.
\]
Additionally:
\[
\iint \limits_D 1 \, dA = A(D)
\]
Combining the previous theorems, if $m \le f(x,y) \le M$ for all $(x,y)$ in $D$,
then:
\[
m \cdot A(D) \le \iint \limits_D f(x,y) \, dA \le M \cdot A(D). 
\]

Sometimes it is easier to represent areas with polar coordinates. If 
$f$ is continous on a polar rectangle $R$ given by
\begin{align}
0 \le a \le r \le b, \nonumber \\ 
\alpha \le \theta \le \beta, \nonumber \\
0 \le \beta - \alpha \le 2\pi \nonumber,
\end{align}
then:
\[
\iint \limits_R f(x,y)\, dA = \int_{\alpha}^{\beta} \int_{a}^{b} f(r\cos\theta, r\sin\theta) \, r \, dr \, d\theta.
\]
To remember the formula:
\begin{center}
    \includegraphics[width=12cm,height=12cm, keepaspectratio]{Images/PolarDoubleIntegration.png}
\end{center}

Similar to cartesian double integration, functions can be used as bounds:
\[
D = \{(r,\theta) \ | \ \alpha \le \theta \le \beta, \ h_1(\theta) \le r \le h_2(\theta)\},  
\]
and:
\[
\iint \limits_D f(x,y) \, dA  = \int_{\alpha}^{\beta} \int_{h_1(\theta)}^{h_2(\theta)} f(r\cos\theta, r\sin\theta) \, r \, dr \, d\theta.
\]

Caculating mass from densities is just as easy as calculating volumes.
Given a density function $\rho (x,y)$, and a 2D object with mass $m$
over a region $D$,
\[
m = \iint \limits_D \rho(x,y) \, dA.
\]
Similarly the moment of an object around the $x$-axis and the $y$-axis:
\[
M_x = \iint \limits_D y \rho(x,y) \, dA, \
M_y = \iint \limits_D x \rho(x,y) \, dA.
 \]
The moment of an object around the $y$-axis would have an $x$ in the integrand.
The center of mass $(\bar{x}, \bar{y})$ must satisfy $m\bar{x} = M_y$ and
$m\bar{y} = M_x$. Therefore, 
\begin{align}
    \bar{x} = \frac{M_y}{m},\nonumber \\ 
    \bar{y} = \frac{M_x}{m}. \nonumber
\end{align}

The moment of inertia has the $x$ or $y$ term squared. The polar moment
of inertia:
\[
I_0 = \iint \limits_D (x^2 + y^2) \rho(x,y) \, dA.
\]
The polar moment has the property $I_0 = I_x + I_y$. The moment of 
inertia of a disk with radius $a$:
\[
I_0 = \frac{1}{2}ma^2.
\]
The radii of gyration $\bar{\bar{x}}$ and $\bar{\bar{y}}$ with respect to
the $y$-axis and $x$-axis respectively satisfy $m\bar{\bar{x}}=I_y$ and 
$m\bar{\bar{y}}=I_x$. The radii of gyration for a disk with radius $a$:
\[
    \bar{\bar{x}}, \bar{\bar{y}} = \frac{1}{2}a.
\]

For a probability density $f(x,y)$:
\[
P((X,Y) \in D) = \iint \limits_D f(x,y) \, dA.
\]
Since the total probability must be one:
\[
1 = \iint \limits_{\mathbb{R}^2} f(x,y) \, dA
\]
 
The area of a surface $z=f(x,y)$, where $f_x$ and $f_y$ are continous:
\[
A(S) = \iint \limits_D \sqrt{[f_x(x,y)]^2 + [f_y(x,y)]^2+1} \, dA.
\]
In polar:
\[
A(S) = \iint  \limits_D \sqrt{[f_x(r\cos\theta,r\sin\theta)]^2 + [f_y(r\cos\theta,r\sin\theta)]^2+1} \, r\,dr \,d\theta.
\]

Given two bounds $z = U_1(x,y)$ and $z = U_2(x,y)$, the triple integral is
\[
\iint \limits_D \int_{U_2(x,y)}^{U_1(x,y)} f(x,y,z) \, dz \, dA.
\]

Whatever first integration you use, find the projection of the volume onto the opposite plane:
if using $z$, find the projection of the volume onto the $xy$-plane. To find
the projection, set the two bounds equal. For the center of mass:
\[
\bar{x} = \frac{M_{yz}}{m},
\] 
and vice versa.

Cylindrical coordinates are defined by a $r$, a $\theta$, and a $z$; Therefore, the $r$
and $\theta$ give a point on the $xy$-plane while the $z$ gives a $z$ coordinate.
Cylindrical triple integrals are very similar to cartesian triple integrals:
\[
    \iiint \limits_E f(x,y,z) \, dV = \int_{\theta_1}^{\theta_2} \int_{r_1}^{r_2} \int_{z_1}^{z_2} f(r,\theta,z) \, r \, dz \, dr \, d\theta.
\]

Spherical coordinates $(\rho, \theta, \phi)$ are defined by $\rho$, a distance from the origin;
$\theta$, an angle from the positive $x$-axis; and $\phi$, an angle from the
positive $z$-axis. They are bounded by the following inequalities:
\begin{gather}
    \rho \ge 0 \nonumber, \\
    0 \le \theta \le 2\pi \nonumber, \\
    0 \le \phi \le \pi \nonumber.
\end{gather} 
For a constant $c$, if $\rho = c$, then the figure is a sphere. If $\theta = c$,
then the figure is a "half" plane. If $\phi = c$, then the figure is a cone.
For converting to cartesian:
\begin{gather}
    x = \rho \sin\phi \cos\theta \nonumber, \\
    y = \rho \sin\phi \sin\theta \nonumber, \\
    z = \rho \cos\phi \nonumber, \\
    \rho^2 = x^2 + y^2 + z^2 \nonumber.
\end{gather}

To evaluate a triple integral using spherical coordinates:
\[
    \iiint \limits_E f(x,y,z) \, dV = \int_{\phi_1}^{\phi_2} \int_{\theta_1}^{\theta_2} \int_{\rho_1}^{\rho_2} f(\rho,\phi,\theta) \, \rho^2\sin\phi \, d\rho \, d\theta \, d\phi.
\]

To find the transformation of a region from a $uv$-plane to an $xy$-plane,
solve for $u$ and $v$, draw the curves formed by $u$ and $v$ at their boundaries,
and then find the interection of these curves. Given multiple equations, 
find a repeated pattern for $u$ and for $v$. Substituting in $u$ and $v$, 
you will be able to see the bounds of $u$ and $v$.

The Jacobian of $x$ and $y$ with respect to $u$ and $v$ is:
{\Huge\[\renewcommand\arraystretch{1.6}
\pdv{(x, y)}{(u, v)} = \begin{vmatrix}
    \pdv{x}{u} & \pdv{x}{v} \\[0.5ex]
    \pdv{y}{u} & \pdv{y}{v}
    \end{vmatrix}.
\]}
The Jacobian gives us the extra factor when converting an integral to
$u$ and $v$.
Therefore,
\[
\iint \limits_R f(x,y) \, dA =
\iint \limits_S f(x(u,v), y(u,v)) \, \abs{\pdv{(x, y)}{(u, v)}} \, du \, dv. 
\]

A reminder: the determinant of a 
$2 \times 2$ matrix $\begin{pmatrix} a & b \\ c & d \end{pmatrix}$ is given by: 
\[ 
\begin{vmatrix} 
a & b \\ 
c & d 
\end{vmatrix} = ad - bc,
\]
and the determinant of a 
$3 \times 3$ matrix $\begin{pmatrix} a & b & c \\ d & e & f \\ g & h & i \end{pmatrix}$ is given by:
\[
\begin{vmatrix}
    a & b & c \\ 
    d & e & f \\ 
    g & h & i
\end{vmatrix} = 
a(ei - fh) - b(di - fg) + c(dh * eg).
\]

\section*{Vector Calculus}

Vector fields often represent fluid flow, electrical currents, and heat flow.
They are defined as $\mathbf{F}(x,y) = P(x,y)\mathbf{i} + Q(x,y)\mathbf{j}
= \left\langle P(x,y), Q(x,y) \right\rangle$.

Gradient fields are a type of vector field. A vector field $\mathbf{F}$ is 
considered conservative if it is the gradient of some other function, 
that is, if there exists a function $f$ such that $\mathbf{F} = \nabla f$. 
The function $f$ is called a potential function of $\mathbf{F}$.

The formula for a line integral on a curve $C$:
\[
\int \limits_C f(x,y,z) \, ds = 
\int_a^b f(x(t), y(t), z(t))
 \sqrt{\left(\frac{dx}{dt}\right)^2 + \left(\frac{dy}{dt}\right)^2 + \left(\frac{dz}{dt}\right)^2} \, dt.
\]
The line integrals with respect to $x$, $y$, and $z$:
\begin{gather}
    \int \limits_C f(x,y,z) \, dx = \int_{a}^{b} f(x(t), y(t), z(t)) \, x'(t) \, dt, \nonumber \\
    \int \limits_C f(x,y,z) \, dy = \int_{a}^{b} f(x(t), y(t), z(t)) \, y'(t) \, dt, \nonumber \\
    \int \limits_C f(x,y,z) \, dz = \int_{a}^{b} f(x(t), y(t), z(t)) \, z'(t) \, dt. \nonumber
\end{gather}
To find a parametric representation of a curve, remember that for $0 \le t \le 1$,
the line segment from $\mathbf{r}_0$ to $\mathbf{r}_1$ is
\[
\mathbf{r}(t) = (1-t)\mathbf{r}_0 + t\mathbf{r}_1.
\]

The work done for moving a particle in a vector field $\mathbf{F}$ on a curve $C$ is
\[
\int \limits_C \mathbf{F} \cdot d\mathbf{r} = 
\int_a^b \mathbf{F}(\mathbf{r}(t)) \cdot \mathbf{r}'(t) \, dt.
\]
Work is positive when the vector field aligns with the curve and negative when
the vector field doesn't align with the curve. Therefore, more work is more negative. 

The fundamental theorem of line integrals states: 
that for a conservative function $\mathbf{F} = \nabla f$,
\[
\int \limits_C \mathbf{F} \, d\mathbf{r} = f(x_2, y_2) - f(x_1, y_1).
\]
This also means, for a conservative function, paths are independent.
This means that a path with the same endpoints and direction
have the same value. If a function is conservative,
and if $\mathbf{F} = P(x,y)\mathbf{i} + Q(x,y)\mathbf{j}$, then
\[
\pdv{P}{y} = \pdv{Q}{x}.
\]

A simple curve is one without intersections,
and a simple closed curve is one that has the beginning and endpoints
and has no intersections.

Green's theorem, where $\mathbf{F} = P(x,y)\mathbf{i} + Q(x,y)\mathbf{j}$:
\[
\varointctrclockwise \limits_C \mathbf{F} \, d\mathbf{r} =
\iint \limits_R [\pdv{Q}{x} - \pdv{P}{y}] \, dA.
\]
A clockwise path would be negative of a counter-clockwise path.
If there is a hole in a disk but both curves are positively oriented,
Green's theorem still works.

The curl of a function $\mathbf{F}$ for 
$\mathbf{F} = P(x,y,z)\mathbf{i} + Q(x,y,z)\mathbf{j} + R(x,y,z)\mathbf{k}$:
\begin{gather}
    \nabla \cross \mathbf{F} = 
    \begin{vmatrix}
        \mathbf{i} & \mathbf{j} & \mathbf{k} \\ 
        \pdv*{}{x} & \pdv*{}{y} & \pdv*{}{z} \\ 
        P(x,y,z) & Q(x,y,z) & R(x,y,z)
    \end{vmatrix} = \nonumber \\
    (\pdv*{R}{y} - \pdv*{Q}{z})\mathbf{i} -
    (\pdv*{R}{x} - \pdv*{P}{z})\mathbf{j} + 
    (\pdv*{Q}{x} - \pdv*{P}{y})\mathbf{k} \nonumber.
\end{gather}
The divergence of the same function: 
\[
\nabla \cdot \mathbf{F} = \pdv{P}{x} + \pdv{Q}{y} + \pdv{R}{z}.
\]

The curl of the gradient of a function with continous second partial derivatives
is the zero vector. This means that the curl of a conservative vector field 
with component functions that are continuous partial derivatives is the zero vector. 
Therefore, if the curl of a vector is the zero vector, then the vector field is conservative.
Curl is zero if a paddle placed at a point moved but didn't rotate around its own axis. 
Curl points in the positive $z$-axis if the curl is counter-clockwise and opposite for clockwise curl.


The divergence of the curl of a function must be the zero vector too because of this property:
$\mathbf{a \cdot (a \cross b)} = 0$. The divergence also represents rate of change 
with respect to time flowing from the points. Divergence is positive if the vectors that
start at the point are longer than the vectors that end at the point and vice versa. 

The Laplace operator: 
\[
\nabla^2 = \nabla \cdot \nabla.
\]
With a function:
\[
\nabla^2 f = \pdv[2]{f}{x} + \pdv[2]{f}{y} + \pdv[2]{f}{z},
\]
with a vector field: 
\[
\nabla^2 \mathbf{F} = \nabla^2 P \mathbf{i} + \nabla^2 Q \mathbf{j} + \nabla^2 R \mathbf{k}.
\]

Also,
\[
\oint \limits_C \mathbf{F \cdot n} \, ds = \iint \limits_D \mbox{div} \ \mathbf{F}(x,y) \, dA
\]

Parametric surfaces are denoted like this:
\[
\mathbf{r}(u,v) = x(u,v)\mathbf{i} + y(u,v)\mathbf{j} + z(u,v)\mathbf{k}.
\]
Grid curves occur when $u$ or $v$ are fixed. To find the tangent plane to the surface at a certain point, find the partial
derivatives with respect to $u$ and $v$ and then find the normal vector from the cross product. 

To find a surface from revolving a function $y=f(x)$:
\begin{gather}
x=x \nonumber \\
y=f(x)\cos\theta \nonumber \\
z = f(x)\sin\theta \nonumber.
\end{gather}

The surface area of a parametric surface defined on $D$:
\[
A(S) = \iint \limits_D |\mathbf{r}_u \cross \mathbf{r}_v| \, dA 
\]
The surface area of a function $z=f(x,y)$:
\[
A(s)= \iint \limits_D \sqrt{1 + \left( \pdv{z}{x} \right) + \left( \pdv{z}{y} \right)} \, dA.
\]
For the first formula $D$ is on the $uv$-plane while in the second formula 
$D$ is on the $xy$-plane.

\end{document}